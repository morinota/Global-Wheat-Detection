# torch.deviceオブジェクトってなんぞや

- 「テンソルを割り当てるデバイスを表す」もの。
- （CPUかGPUか、GPUが複数あるときにはどのGPUか）

# テンソルをデバイスに渡す

これらのdeviceオブジェクトは今も述べたように、「テンソルを割り当てるデバイスを表す」もの。
既存のTensorオブジェクトは、toメソッドにdeviceオブジェクトを渡すことで、対応するデバイス（CPUかGPU）にその内容が転送される。

```python
x = torch.tensor([1, 2, 3])
x = x.to(torch.device('cuda:0'))  # テンソルをGPU0に転送して、その結果をxに代入
print(x)
```

注意すべき点は、toメソッドの戻り値を何かの変数に代入しなければ、それは捨てられてしまうこと。上のコードでは、変数xに代入し直している。

もう一つ重要な点は、「**ある処理を行うに当たって、必要となる全ての要素が同じデバイス上になければならない**」こと。
つまり、CPU上に割り当てられているTensorと、GPU上に割り当てられているTensorとを加算するといったことはできません。

このことから、ニューラルネットワークモデルの学習や、ニューラルネットワークモデルを利用した推測においては、必要なものを全て同じデバイスに転送しておかなければならない。
# 参考

- https://atmarkit.itmedia.co.jp/ait/articles/2008/28/news030.html
